{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yyjshuju/gae/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MgVU71mGqkd"
      },
      "source": [
        "# layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9nUWGNLZJ3Gn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.modules.module import Module\n",
        "from torch.nn.parameter import Parameter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jC8UvNRqJm5L"
      },
      "outputs": [],
      "source": [
        "class SparseMM(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    Sparse x dense matrix multiplication with autograd support.\n",
        "\n",
        "    Implementation by Soumith Chintala:\n",
        "    https://discuss.pytorch.org/t/does-pytorch-support-autograd-on-sparse-matrix/6156/7\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, matrix1, matrix2):\n",
        "        ctx.save_for_backward(matrix1, matrix2)\n",
        "        return torch.mm(matrix1, matrix2)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        matrix1, matrix2 = ctx.saved_tensors\n",
        "        grad_matrix1 = grad_matrix2 = None\n",
        "\n",
        "        if ctx.needs_input_grad[0]:\n",
        "            grad_matrix1 = torch.mm(grad_output, matrix2.t())\n",
        "\n",
        "        if ctx.needs_input_grad[1]:\n",
        "            grad_matrix2 = torch.mm(matrix1.t(), grad_output)\n",
        "\n",
        "        return grad_matrix1, grad_matrix2\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "  Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "  \"\"\"\n",
        "\n",
        "class GraphConvolution(Module):\n",
        "    def __init__(self, in_features, out_features, dropout=0., act=F.relu):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.dropout = dropout\n",
        "        self.sparse_mm = SparseMM.apply\n",
        "        self.act = act\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.weight)\n",
        "\n",
        "    def forward(self, input, adj):\n",
        "        input = F.dropout(input, self.dropout, self.training)\n",
        "        # support = torch.mm(input, self.weight)\n",
        "        # output = torch.spmm(adj, support)\n",
        "        support = self.sparse_mm(input, self.weight)\n",
        "        output = self.sparse_mm(adj, support)\n",
        "        output = self.act(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg2q-Ew514HV"
      },
      "source": [
        "# **Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXMoEK1xKHnd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.nn.init as init\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpNyXsBNKZn_"
      },
      "outputs": [],
      "source": [
        "class GCNModelVAE(nn.Module):\n",
        "    def __init__(self, input_feat_dim, hidden_dim,hidden_dim1, hidden_dim2, hidden_dim3,hidden_dim4, dropout):\n",
        "        super(GCNModelVAE, self).__init__()\n",
        "        self.gc1 = GraphConvolution(input_feat_dim, hidden_dim1, dropout, act=F.relu)\n",
        "        self.gc2 = GraphConvolution(hidden_dim1, hidden_dim2, dropout, act=lambda x: x)\n",
        "        self.gc3 = GraphConvolution(hidden_dim1, hidden_dim2, dropout, act=lambda x: x)\n",
        "\n",
        "        self.dense = LinearNet(hidden_dim2, hidden_dim3, dropout, act=F.sigmoid)\n",
        "        self.dense1 = LinearNet(hidden_dim3, 3, dropout, act=F.sigmoid)#cora 7/pumb 3/ci 6\n",
        "        self.dc = InnerProductDecoder(dropout, act=lambda x: x)\n",
        "\n",
        "    def encode(self, x, adj):\n",
        "                hidden1 = self.gc1(x, adj)\n",
        "                return self.gc2(hidden1, adj), self.gc3(hidden1, adj)\n",
        "                # return self.dense1(hidden1, adj), self.dense2(hidden1, adj)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = torch.exp(logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        mu, logvar = self.encode(x, adj)\n",
        "        mu = self.dense(mu)\n",
        "        logvar = self.dense(logvar)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.dc(z),self.dense1(z), mu, logvar\n",
        "\n",
        "class GCNModelVAEen(nn.Module):\n",
        "    def __init__(self, input_feat_dim, hidden_dim,hidden_dim1, hidden_dim2, hidden_dim3,hidden_dim4, dropout):\n",
        "        super(GCNModelVAEen, self).__init__()\n",
        "        self.gc1 = GraphConvolution(input_feat_dim, hidden_dim1, dropout, act=F.relu)\n",
        "        self.gc2 = GraphConvolution(hidden_dim1, hidden_dim2, dropout, act=lambda x: x)\n",
        "        self.gc3 = GraphConvolution(hidden_dim1, hidden_dim2, dropout, act=lambda x: x)\n",
        "    def encode(self, x, adj):\n",
        "        hidden1 = self.gc1(x, adj)\n",
        "        return self.gc2(hidden1, adj), self.gc3(hidden1, adj)\n",
        "                # return self.dense1(hidden1, adj), self.dense2(hidden1, adj)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = torch.exp(logvar)\n",
        "            eps = torch.randn_like(std)\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        mu, logvar = self.encode(x, adj)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return mu, logvar\n",
        "\n",
        "    \"\"\"Decoder for using inner product for prediction.\"\"\"\n",
        "class LinearNet(nn.Module):\n",
        "    def __init__(self, n_feature,out_features,dropout, act=F.relu):\n",
        "        super(LinearNet, self).__init__()\n",
        "        self.linear = nn.Linear(n_feature, out_features)\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "    # forward 定义前向传播\n",
        "    def forward(self, x):\n",
        "        y = self.linear(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "class InnerProductDecoder(nn.Module):\n",
        "    def __init__(self, dropout, act=torch.sigmoid):\n",
        "        super(InnerProductDecoder, self).__init__()\n",
        "        self.dropout = dropout\n",
        "        self.act = act\n",
        "\n",
        "    def forward(self, z):\n",
        "        z = F.dropout(z, self.dropout, training=self.training)\n",
        "        adj = self.act(torch.mm(z, z.t()))\n",
        "        return adj\n",
        "\n",
        "class Discriminator(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.lin1 = torch.nn.Linear(in_channels, hidden_channels)\n",
        "        self.lin2 = torch.nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.lin3 = torch.nn.Linear(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.lin1(x))\n",
        "        x = F.relu(self.lin2(x))\n",
        "        x = self.lin3(x)\n",
        "        return x\n",
        "class VEncoder(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(VEncoder, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels, 2 * out_channels, cached=True)\n",
        "        self.conv_mu = GCNConv(2 * out_channels, out_channels, cached=True)\n",
        "        self.conv_logstd = GCNConv(2 * out_channels, out_channels, cached=True)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        return self.conv_mu(x, edge_index), self.conv_logstd(x, edge_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NYjeONT2FNf"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UioauDCi2c_y"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "import pickle\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "from scipy import sparse\n",
        "import torch\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import os.path as osp\n",
        "import itertools\n",
        "from collections import namedtuple\n",
        "Data = namedtuple('Data', ['x', 'y', 'adjacency',\n",
        "                           'train_mask', 'val_mask', 'test_mask'])\n",
        "def sample_mask(idx, l):\n",
        "    \"\"\"Create mask.\"\"\"\n",
        "    mask = np.zeros(l)\n",
        "    mask[idx] = 1\n",
        "    return np.array(mask, dtype=np.bool)\n",
        "\n",
        "def tensor_from_numpy(x, device):\n",
        "    return torch.from_numpy(x).to(device)\n",
        "\n",
        "def load_data(dataset):\n",
        "    names = ['x', 'tx', 'allx', 'y', 'ty', 'ally', 'graph']\n",
        "    objects = []\n",
        "    for i in range(len(names)):\n",
        "        with open(\"drive/MyDrive/data/ind.{}.{}\".format(dataset, names[i]), 'rb') as rf:\n",
        "            u = pkl._Unpickler(rf)\n",
        "            u.encoding = 'latin1'\n",
        "            cur_data = u.load()\n",
        "            objects.append(cur_data)\n",
        "    x, tx, allx, y, ty, ally, graph= tuple(objects)\n",
        "    test_idx_reorder = parse_index_file(\n",
        "        \"data/ind.{}.test.index\".format(dataset))\n",
        "    test_idx_range = np.sort(test_idx_reorder)\n",
        "\n",
        "    if dataset == 'citeseer':\n",
        "        # Fix citeseer dataset (there are some isolated nodes in the graph)\n",
        "        # Find isolated nodes, add them as zero-vecs into the right position\n",
        "        test_idx_range_full = range(min(test_idx_reorder), max(test_idx_reorder)+1)\n",
        "        tx_extended = sp.lil_matrix((len(test_idx_range_full), x.shape[1]))\n",
        "        tx_extended[test_idx_range-min(test_idx_range), :] = tx\n",
        "        tx = tx_extended\n",
        "        ty_extended = np.zeros((len(test_idx_range_full), y.shape[1]))\n",
        "        ty_extended[test_idx_range-min(test_idx_range), :] = ty\n",
        "        ty = ty_extended\n",
        "\n",
        "    train_index = np.arange(y.shape[0])\n",
        "    val_index = np.arange(y.shape[0], y.shape[0] + 500)\n",
        "    stx = tx.A\n",
        "    sallx=allx.A\n",
        "    x1 = np.concatenate((sallx, stx), axis=0)\n",
        "    y1= np.concatenate((ally, ty), axis=0).argmax(axis=1)\n",
        "\n",
        "    x1[test_idx_reorder] = x1[test_idx_range]\n",
        "    y1[test_idx_reorder] = y1[test_idx_range]\n",
        "    num_nodes = x1.shape[0]\n",
        "\n",
        "    train_mask = np.zeros(num_nodes, dtype=np.bool)\n",
        "    val_mask = np.zeros(num_nodes, dtype=np.bool)\n",
        "    test_mask = np.zeros(num_nodes, dtype=np.bool)\n",
        "    train_mask[train_index] = True\n",
        "    val_mask[val_index] = True\n",
        "    test_mask[test_idx_reorder] = True\n",
        "\n",
        "    features = sp.vstack((allx, tx)).tolil()\n",
        "    features[test_idx_reorder, :] = features[test_idx_range, :]\n",
        "    features = torch.FloatTensor(np.array(features.todense()))\n",
        "    adj = nx.adjacency_matrix(nx.from_dict_of_lists(graph))\n",
        "    # return adj, features\n",
        "    return x1, y1, train_mask, val_mask, test_mask, adj, features\n",
        "\n",
        "def parse_index_file(filename):\n",
        "    index = []\n",
        "    for line in open(filename):\n",
        "        index.append(int(line.strip()))\n",
        "    return index\n",
        "\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "\n",
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    num_test = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val = int(np.floor(edges.shape[0] / 20.))\n",
        "\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], edges_all):\n",
        "            continue\n",
        "        if test_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "                continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        if idx_i == idx_j:\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], train_edges):\n",
        "            continue\n",
        "        if ismember([idx_i, idx_j], val_edges):\n",
        "            continue\n",
        "        if ismember([idx_j, idx_i], val_edges):\n",
        "            continue\n",
        "        if val_edges_false:\n",
        "            if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "                continue\n",
        "            if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "                continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    assert ~ismember(test_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges_false, edges_all)\n",
        "    assert ~ismember(val_edges, train_edges)\n",
        "    assert ~ismember(test_edges, train_edges)\n",
        "    assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false\n",
        "\n",
        "\n",
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    # return sparse_to_tuple(adj_normalized)\n",
        "    return sparse_mx_to_torch_sparse_tensor(adj_normalized)\n",
        "\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64))\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape)\n",
        "\n",
        "def plot_results(results, test_freq, path='results.png'):\n",
        "    # Init\n",
        "    plt.close('all')\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "\n",
        "    x_axis_train = range(len(results['train_elbo']))\n",
        "    x_axis_test = range(0, len(x_axis_train), test_freq)\n",
        "    # Elbo\n",
        "    ax = fig.add_subplot(2, 2, 1)\n",
        "    ax.plot(x_axis_train, results['train_elbo'])\n",
        "    ax.set_ylabel('Loss (ELBO)')\n",
        "    ax.set_title('Loss (ELBO)')\n",
        "    ax.legend(['Train'], loc='upper right')\n",
        "\n",
        "    # Accuracy\n",
        "    ax = fig.add_subplot(2, 2, 2)\n",
        "    ax.plot(x_axis_train, results['accuracy_train'])\n",
        "    ax.plot(x_axis_test, results['accuracy_test'])\n",
        "    ax.set_ylabel('Accuracy')\n",
        "    ax.set_title('Accuracy')\n",
        "    ax.legend(['Train', 'Test'], loc='lower right')\n",
        "\n",
        "    # ROC\n",
        "    ax = fig.add_subplot(2, 2, 3)\n",
        "    ax.plot(x_axis_train, results['roc_train'])\n",
        "    ax.plot(x_axis_test, results['roc_test'])\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('ROC AUC')\n",
        "    ax.set_title('ROC AUC')\n",
        "    ax.legend(['Train', 'Test'], loc='lower right')\n",
        "\n",
        "    # Precision\n",
        "    ax = fig.add_subplot(2, 2, 4)\n",
        "    ax.plot(x_axis_train, results['ap_train'])\n",
        "    ax.plot(x_axis_test, results['ap_test'])\n",
        "    ax.set_xlabel('Epoch')\n",
        "    ax.set_ylabel('Precision')\n",
        "    ax.set_title('Precision')\n",
        "    ax.legend(['Train', 'Test'], loc='lower right')\n",
        "\n",
        "    # Save\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(path)\n",
        "\n",
        "def  get_roc_score(emb, adj_orig, edges_pos, edges_neg):\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "    # Predict on test set of edges\n",
        "    adj_rec = np.dot(emb, emb.T)\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]]))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "    accuracy = accuracy_score((preds_all > 0.5).astype(float), labels_all)\n",
        "    return roc_score, ap_score, accuracy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqB8PC202iFV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vaR-d3D4px2",
        "outputId": "8ae9a650-473b-4252-ac30-1c29ae0dd3a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.11.0+cu113\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 2.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 37 kB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyFVW1qK27-j",
        "outputId": "74edc9fd-6127-4996-df5f-89bddc9a3c9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using pubmed dataset\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:62: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:63: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ],
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import os.path as osp\n",
        "import argparse\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch import optim\n",
        "from collections import defaultdict\n",
        "# from model import GCNModelVAE,Discriminator\n",
        "# from optimizer import loss_function\n",
        "# from utils import load_data, mask_test_edges, preprocess_graph, get_roc_score, tensor_from_numpy\n",
        "import matplotlib.pyplot as plt\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn.models.autoencoder import ARGVA\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "\n",
        "\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model', type=str, default='gcn_vae')\n",
        "parser.add_argument('--seed', type=int, default=42)\n",
        "parser.add_argument('--epochs', type=int, default=200)\n",
        "parser.add_argument('--hidden', type=int, default=50)\n",
        "parser.add_argument('--hidden1', type=int, default=64)\n",
        "parser.add_argument('--hidden2', type=int, default=32)\n",
        "parser.add_argument('--hidden3', type=int, default=16)\n",
        "parser.add_argument('--hidden4', type=int, default=32)\n",
        "parser.add_argument('--lr', type=float, default=0.001)#0.0261/0.043\n",
        "parser.add_argument('--dropout', type=float, default=0.00)\n",
        "parser.add_argument('--dataset-str', type=str, default='cora')\n",
        "parser.add_argument('--test_freq', type=int, default='10')\n",
        "# args = parser.parse_args()\n",
        "parser.parse_known_args()[0]\n",
        "\n",
        "# Cora数据集(引文网络)由机器学习论文组成\n",
        "# PubMed数据集(引文网络)包括来自Pubmed数据库的19717篇关于糖尿病的科学出版物，分为三类\n",
        "# CiteSeer数据集(引文网络)中，论文分为六类\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} dataset\".format('pubmed'))\n",
        "# adj, features = load_data(args.dataset_str)\n",
        "x, y, train_mask, val_mask, test_mask, adj, features= load_data('pubmed')\n",
        "n_nodes, feat_dim = features.shape\n",
        "# dataset = load_data2().data\n",
        "node_feature = x / x.sum(1, keepdims=True)  # 归一化数据，使得每一行和为1\n",
        "tensor_x = tensor_from_numpy(node_feature, DEVICE)\n",
        "tensor_y = tensor_from_numpy(y, DEVICE)\n",
        "tensor_train_mask = tensor_from_numpy(train_mask, DEVICE)\n",
        "tensor_val_mask = tensor_from_numpy(val_mask, DEVICE)\n",
        "tensor_test_mask = tensor_from_numpy(test_mask, DEVICE)\n",
        "num_nodes, input_dim = node_feature.shape\n",
        "# normalize_adjacency = load_data2.normalization(dataset.adjacency)\n",
        "# indices = torch.from_numpy(np.asarray([normalize_adjacency.row,\n",
        "#                                        normalize_adjacency.col]).astype('int64')).long()\n",
        "# values = torch.from_numpy(normalize_adjacency.data.astype(np.float32))\n",
        "# tensor_adjacency = torch.sparse.FloatTensor(indices, values,\n",
        "#                                             (num_nodes, num_nodes)).to(DEVICE)\n",
        "\n",
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n",
        "\n",
        "\n",
        "adj_norm = preprocess_graph(adj)\n",
        "# adj_label = adj + sp.eye(adj.shape[0])\n",
        "# adj_label = torch.FloatTensor(adj_label.toarray())\n",
        "# pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "# norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "# model = GCNModelVAE(feat_dim, args.hidden, args.hidden1, args.hidden2, args.hidden3, args.hidden4, args.dropout)\n",
        "# optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "criterion = nn.CrossEntropyLoss().to(DEVICE)\n",
        "    # optimizer = optim.AdaGrad(model.parameters(), lr=args.lr) RAdam\n",
        "encoder = GCNModelVAEen(feat_dim, 50, 64, 32, 16, 32, 0.00)\n",
        "model = GCNModelVAE(feat_dim, 50, 64, 32, 16, 32, 0.00)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X4BlJG0T8g4K",
        "outputId": "aa8202ca-3f61-48f8-b8e4-0c319704536e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 train_loss= 1.20318 train_acc= 0.33333 train_acc2= 0.41600 time= 1.80448\n",
            "Epoch: 0002 train_loss= 1.09407 train_acc= 0.33333 train_acc2= 0.41600 time= 3.43146\n",
            "Epoch: 0003 train_loss= 1.08675 train_acc= 0.33333 train_acc2= 0.41600 time= 5.04130\n",
            "Epoch: 0004 train_loss= 1.07835 train_acc= 0.33333 train_acc2= 0.41600 time= 6.62564\n",
            "Epoch: 0005 train_loss= 1.06861 train_acc= 0.35000 train_acc2= 0.43000 time= 8.21668\n",
            "Epoch: 0006 train_loss= 1.05731 train_acc= 0.40000 train_acc2= 0.48400 time= 9.80702\n",
            "Epoch: 0007 train_loss= 1.04420 train_acc= 0.51667 train_acc2= 0.62800 time= 11.39638\n",
            "Epoch: 0008 train_loss= 1.02903 train_acc= 0.51667 train_acc2= 0.65000 time= 13.01228\n",
            "Epoch: 0009 train_loss= 1.01159 train_acc= 0.51667 train_acc2= 0.62200 time= 14.58122\n",
            "Epoch: 0010 train_loss= 0.99174 train_acc= 0.51667 train_acc2= 0.59400 time= 16.15031\n",
            "Epoch: 0011 train_loss= 0.96938 train_acc= 0.53333 train_acc2= 0.58400 time= 17.73071\n",
            "Epoch: 0012 train_loss= 0.94438 train_acc= 0.55000 train_acc2= 0.58600 time= 19.32198\n",
            "Epoch: 0013 train_loss= 0.91651 train_acc= 0.58333 train_acc2= 0.60400 time= 20.90878\n",
            "Epoch: 0014 train_loss= 0.88537 train_acc= 0.61667 train_acc2= 0.63800 time= 22.49861\n",
            "Epoch: 0015 train_loss= 0.85053 train_acc= 0.66667 train_acc2= 0.69400 time= 24.09381\n",
            "Epoch: 0016 train_loss= 0.81182 train_acc= 0.75000 train_acc2= 0.73600 time= 25.67670\n",
            "Epoch: 0017 train_loss= 0.76975 train_acc= 0.78333 train_acc2= 0.77400 time= 27.26423\n",
            "Epoch: 0018 train_loss= 0.72577 train_acc= 0.85000 train_acc2= 0.80200 time= 28.84737\n",
            "Epoch: 0019 train_loss= 0.68211 train_acc= 0.85000 train_acc2= 0.82000 time= 30.42336\n",
            "Epoch: 0020 train_loss= 0.64121 train_acc= 0.86667 train_acc2= 0.82600 time= 32.03107\n",
            "Epoch: 0021 train_loss= 0.60464 train_acc= 0.88333 train_acc2= 0.83000 time= 33.60238\n",
            "Epoch: 0022 train_loss= 0.57248 train_acc= 0.88333 train_acc2= 0.84000 time= 35.20454\n",
            "Epoch: 0023 train_loss= 0.54365 train_acc= 0.88333 train_acc2= 0.84000 time= 36.78166\n",
            "Epoch: 0024 train_loss= 0.51742 train_acc= 0.88333 train_acc2= 0.83800 time= 38.37111\n",
            "Epoch: 0025 train_loss= 0.49428 train_acc= 0.86667 train_acc2= 0.84400 time= 39.97147\n",
            "Epoch: 0026 train_loss= 0.47530 train_acc= 0.86667 train_acc2= 0.84800 time= 41.52977\n",
            "Epoch: 0027 train_loss= 0.46104 train_acc= 0.88333 train_acc2= 0.85200 time= 43.12141\n",
            "Epoch: 0028 train_loss= 0.45060 train_acc= 0.88333 train_acc2= 0.85200 time= 44.70385\n",
            "Epoch: 0029 train_loss= 0.44172 train_acc= 0.88333 train_acc2= 0.85600 time= 46.29657\n",
            "Epoch: 0030 train_loss= 0.43370 train_acc= 0.90000 train_acc2= 0.86000 time= 47.88788\n",
            "Epoch: 0031 train_loss= 0.42746 train_acc= 0.90000 train_acc2= 0.85800 time= 49.46198\n",
            "Epoch: 0032 train_loss= 0.42314 train_acc= 0.90000 train_acc2= 0.86200 time= 51.03780\n",
            "Epoch: 0033 train_loss= 0.42054 train_acc= 0.90000 train_acc2= 0.86400 time= 52.61537\n",
            "Epoch: 0034 train_loss= 0.41847 train_acc= 0.90000 train_acc2= 0.86600 time= 54.20622\n",
            "Epoch: 0035 train_loss= 0.41489 train_acc= 0.90000 train_acc2= 0.86800 time= 55.79818\n",
            "Epoch: 0036 train_loss= 0.40978 train_acc= 0.90000 train_acc2= 0.87200 time= 57.36187\n",
            "Epoch: 0037 train_loss= 0.40446 train_acc= 0.90000 train_acc2= 0.87400 time= 58.95218\n",
            "Epoch: 0038 train_loss= 0.39944 train_acc= 0.90000 train_acc2= 0.88000 time= 60.52077\n",
            "Epoch: 0039 train_loss= 0.39453 train_acc= 0.90000 train_acc2= 0.88200 time= 62.10169\n",
            "Epoch: 0040 train_loss= 0.38922 train_acc= 0.90000 train_acc2= 0.88000 time= 63.69345\n",
            "Epoch: 0041 train_loss= 0.38313 train_acc= 0.90000 train_acc2= 0.88200 time= 65.27647\n",
            "Epoch: 0042 train_loss= 0.37690 train_acc= 0.90000 train_acc2= 0.88400 time= 66.84722\n",
            "Epoch: 0043 train_loss= 0.37132 train_acc= 0.90000 train_acc2= 0.88400 time= 68.40734\n",
            "Epoch: 0044 train_loss= 0.36656 train_acc= 0.90000 train_acc2= 0.88600 time= 69.97177\n",
            "Epoch: 0045 train_loss= 0.36241 train_acc= 0.90000 train_acc2= 0.88600 time= 71.55139\n",
            "Epoch: 0046 train_loss= 0.35875 train_acc= 0.91667 train_acc2= 0.88400 time= 73.13569\n",
            "Epoch: 0047 train_loss= 0.35560 train_acc= 0.91667 train_acc2= 0.88200 time= 74.73918\n",
            "Epoch: 0048 train_loss= 0.35316 train_acc= 0.91667 train_acc2= 0.88600 time= 76.30778\n",
            "Epoch: 0049 train_loss= 0.35138 train_acc= 0.91667 train_acc2= 0.88800 time= 77.87709\n",
            "Epoch: 0050 train_loss= 0.34983 train_acc= 0.91667 train_acc2= 0.88800 time= 79.42649\n",
            "Epoch: 0051 train_loss= 0.34818 train_acc= 0.91667 train_acc2= 0.89200 time= 80.99390\n",
            "Epoch: 0052 train_loss= 0.34646 train_acc= 0.91667 train_acc2= 0.89600 time= 82.55076\n",
            "Epoch: 0053 train_loss= 0.34478 train_acc= 0.91667 train_acc2= 0.89600 time= 84.11488\n",
            "Epoch: 0054 train_loss= 0.34323 train_acc= 0.91667 train_acc2= 0.89600 time= 85.66256\n",
            "Epoch: 0055 train_loss= 0.34173 train_acc= 0.91667 train_acc2= 0.89600 time= 87.25468\n",
            "Epoch: 0056 train_loss= 0.34006 train_acc= 0.91667 train_acc2= 0.89800 time= 88.80935\n",
            "Epoch: 0057 train_loss= 0.33819 train_acc= 0.91667 train_acc2= 0.89600 time= 90.37714\n",
            "Epoch: 0058 train_loss= 0.33626 train_acc= 0.91667 train_acc2= 0.89600 time= 91.93919\n",
            "Epoch: 0059 train_loss= 0.33440 train_acc= 0.91667 train_acc2= 0.89800 time= 93.51246\n",
            "Epoch: 0060 train_loss= 0.33265 train_acc= 0.91667 train_acc2= 0.89800 time= 95.06995\n",
            "Epoch: 0061 train_loss= 0.33095 train_acc= 0.93333 train_acc2= 0.89800 time= 96.63883\n",
            "Epoch: 0062 train_loss= 0.32923 train_acc= 0.93333 train_acc2= 0.89800 time= 98.23141\n",
            "Epoch: 0063 train_loss= 0.32754 train_acc= 0.93333 train_acc2= 0.89800 time= 99.80341\n",
            "Epoch: 0064 train_loss= 0.32595 train_acc= 0.93333 train_acc2= 0.89600 time= 101.35914\n",
            "Epoch: 0065 train_loss= 0.32449 train_acc= 0.93333 train_acc2= 0.89400 time= 102.93603\n",
            "Epoch: 0066 train_loss= 0.32311 train_acc= 0.93333 train_acc2= 0.89400 time= 104.50321\n",
            "Epoch: 0067 train_loss= 0.32177 train_acc= 0.95000 train_acc2= 0.89600 time= 106.06432\n",
            "Epoch: 0068 train_loss= 0.32050 train_acc= 0.95000 train_acc2= 0.89600 time= 107.64197\n",
            "Epoch: 0069 train_loss= 0.31933 train_acc= 0.95000 train_acc2= 0.89600 time= 109.22076\n",
            "Epoch: 0070 train_loss= 0.31823 train_acc= 0.95000 train_acc2= 0.89600 time= 110.78249\n",
            "Epoch: 0071 train_loss= 0.31714 train_acc= 0.95000 train_acc2= 0.89600 time= 112.34388\n",
            "Epoch: 0072 train_loss= 0.31602 train_acc= 0.95000 train_acc2= 0.89600 time= 113.92033\n",
            "Epoch: 0073 train_loss= 0.31489 train_acc= 0.95000 train_acc2= 0.89200 time= 115.47000\n",
            "Epoch: 0074 train_loss= 0.31378 train_acc= 0.95000 train_acc2= 0.89200 time= 117.01967\n",
            "Epoch: 0075 train_loss= 0.31269 train_acc= 0.95000 train_acc2= 0.89200 time= 118.58706\n",
            "Epoch: 0076 train_loss= 0.31158 train_acc= 0.95000 train_acc2= 0.89400 time= 120.17297\n",
            "Epoch: 0077 train_loss= 0.31047 train_acc= 0.95000 train_acc2= 0.89400 time= 121.74518\n",
            "Epoch: 0078 train_loss= 0.30938 train_acc= 0.95000 train_acc2= 0.89400 time= 123.30875\n",
            "Epoch: 0079 train_loss= 0.30834 train_acc= 0.95000 train_acc2= 0.89800 time= 124.88286\n",
            "Epoch: 0080 train_loss= 0.30734 train_acc= 0.95000 train_acc2= 0.89800 time= 126.43859\n",
            "Epoch: 0081 train_loss= 0.30635 train_acc= 0.93333 train_acc2= 0.89800 time= 128.00013\n",
            "Epoch: 0082 train_loss= 0.30540 train_acc= 0.93333 train_acc2= 0.89800 time= 129.55530\n",
            "Epoch: 0083 train_loss= 0.30448 train_acc= 0.93333 train_acc2= 0.90000 time= 131.14392\n",
            "Epoch: 0084 train_loss= 0.30358 train_acc= 0.93333 train_acc2= 0.89800 time= 132.70057\n",
            "Epoch: 0085 train_loss= 0.30268 train_acc= 0.95000 train_acc2= 0.89800 time= 134.27036\n",
            "Epoch: 0086 train_loss= 0.30179 train_acc= 0.95000 train_acc2= 0.89600 time= 135.81250\n",
            "Epoch: 0087 train_loss= 0.30092 train_acc= 0.95000 train_acc2= 0.89600 time= 137.36684\n",
            "Epoch: 0088 train_loss= 0.30007 train_acc= 0.95000 train_acc2= 0.89600 time= 138.89883\n",
            "Epoch: 0089 train_loss= 0.29922 train_acc= 0.95000 train_acc2= 0.89600 time= 140.47177\n",
            "Epoch: 0090 train_loss= 0.29838 train_acc= 0.95000 train_acc2= 0.90000 time= 142.03259\n",
            "Epoch: 0091 train_loss= 0.29756 train_acc= 0.95000 train_acc2= 0.89800 time= 143.57508\n",
            "Epoch: 0092 train_loss= 0.29676 train_acc= 0.95000 train_acc2= 0.89800 time= 145.12125\n",
            "Epoch: 0093 train_loss= 0.29596 train_acc= 0.95000 train_acc2= 0.89800 time= 146.69898\n",
            "Epoch: 0094 train_loss= 0.29517 train_acc= 0.95000 train_acc2= 0.89800 time= 148.24075\n",
            "Epoch: 0095 train_loss= 0.29440 train_acc= 0.95000 train_acc2= 0.90000 time= 149.79343\n",
            "Epoch: 0096 train_loss= 0.29363 train_acc= 0.95000 train_acc2= 0.90000 time= 151.36402\n",
            "Epoch: 0097 train_loss= 0.29288 train_acc= 0.95000 train_acc2= 0.90000 time= 152.96985\n",
            "Epoch: 0098 train_loss= 0.29213 train_acc= 0.95000 train_acc2= 0.90000 time= 154.53781\n",
            "Epoch: 0099 train_loss= 0.29140 train_acc= 0.95000 train_acc2= 0.90000 time= 156.10484\n",
            "Epoch: 0100 train_loss= 0.29067 train_acc= 0.95000 train_acc2= 0.90000 time= 157.64983\n",
            "Epoch: 0101 train_loss= 0.28995 train_acc= 0.95000 train_acc2= 0.90000 time= 159.21542\n",
            "Epoch: 0102 train_loss= 0.28923 train_acc= 0.95000 train_acc2= 0.90000 time= 160.74981\n",
            "Epoch: 0103 train_loss= 0.28852 train_acc= 0.95000 train_acc2= 0.90200 time= 162.31643\n",
            "Epoch: 0104 train_loss= 0.28782 train_acc= 0.95000 train_acc2= 0.90600 time= 163.87644\n",
            "Epoch: 0105 train_loss= 0.28712 train_acc= 0.95000 train_acc2= 0.90600 time= 165.45953\n",
            "Epoch: 0106 train_loss= 0.28642 train_acc= 0.95000 train_acc2= 0.90800 time= 167.01479\n",
            "Epoch: 0107 train_loss= 0.28574 train_acc= 0.95000 train_acc2= 0.90800 time= 168.58281\n",
            "Epoch: 0108 train_loss= 0.28506 train_acc= 0.95000 train_acc2= 0.90800 time= 170.13130\n",
            "Epoch: 0109 train_loss= 0.28439 train_acc= 0.95000 train_acc2= 0.90600 time= 171.70222\n",
            "Epoch: 0110 train_loss= 0.28372 train_acc= 0.95000 train_acc2= 0.90600 time= 173.25138\n",
            "Epoch: 0111 train_loss= 0.28305 train_acc= 0.95000 train_acc2= 0.90600 time= 174.81111\n",
            "Epoch: 0112 train_loss= 0.28239 train_acc= 0.95000 train_acc2= 0.90600 time= 176.35765\n",
            "Epoch: 0113 train_loss= 0.28173 train_acc= 0.95000 train_acc2= 0.90800 time= 177.92331\n",
            "Epoch: 0114 train_loss= 0.28107 train_acc= 0.95000 train_acc2= 0.91000 time= 179.45602\n",
            "Epoch: 0115 train_loss= 0.28042 train_acc= 0.95000 train_acc2= 0.91200 time= 181.03430\n",
            "Epoch: 0116 train_loss= 0.27977 train_acc= 0.95000 train_acc2= 0.91200 time= 182.57951\n",
            "Epoch: 0117 train_loss= 0.27912 train_acc= 0.95000 train_acc2= 0.91200 time= 184.16072\n",
            "Epoch: 0118 train_loss= 0.27848 train_acc= 0.95000 train_acc2= 0.91200 time= 185.68911\n",
            "Epoch: 0119 train_loss= 0.27784 train_acc= 0.95000 train_acc2= 0.91400 time= 187.22351\n",
            "Epoch: 0120 train_loss= 0.27719 train_acc= 0.95000 train_acc2= 0.91400 time= 188.73400\n",
            "Epoch: 0121 train_loss= 0.27656 train_acc= 0.95000 train_acc2= 0.91400 time= 190.26958\n",
            "Epoch: 0122 train_loss= 0.27592 train_acc= 0.95000 train_acc2= 0.91400 time= 191.78629\n",
            "Epoch: 0123 train_loss= 0.27528 train_acc= 0.95000 train_acc2= 0.91400 time= 193.35445\n",
            "Epoch: 0124 train_loss= 0.27465 train_acc= 0.95000 train_acc2= 0.91200 time= 194.88286\n",
            "Epoch: 0125 train_loss= 0.27402 train_acc= 0.95000 train_acc2= 0.91200 time= 196.42421\n",
            "Epoch: 0126 train_loss= 0.27339 train_acc= 0.95000 train_acc2= 0.91200 time= 197.94676\n",
            "Epoch: 0127 train_loss= 0.27276 train_acc= 0.95000 train_acc2= 0.91200 time= 199.49809\n",
            "Epoch: 0128 train_loss= 0.27213 train_acc= 0.95000 train_acc2= 0.91400 time= 201.04856\n",
            "Epoch: 0129 train_loss= 0.27150 train_acc= 0.95000 train_acc2= 0.91400 time= 202.60357\n",
            "Epoch: 0130 train_loss= 0.27087 train_acc= 0.95000 train_acc2= 0.91600 time= 204.12921\n",
            "Epoch: 0131 train_loss= 0.27024 train_acc= 0.95000 train_acc2= 0.91400 time= 205.70036\n",
            "Epoch: 0132 train_loss= 0.26962 train_acc= 0.95000 train_acc2= 0.91400 time= 207.23063\n",
            "Epoch: 0133 train_loss= 0.26899 train_acc= 0.95000 train_acc2= 0.91400 time= 208.77404\n",
            "Epoch: 0134 train_loss= 0.26836 train_acc= 0.95000 train_acc2= 0.91400 time= 210.29850\n",
            "Epoch: 0135 train_loss= 0.26773 train_acc= 0.95000 train_acc2= 0.91400 time= 211.86108\n",
            "Epoch: 0136 train_loss= 0.26710 train_acc= 0.95000 train_acc2= 0.91400 time= 213.38327\n",
            "Epoch: 0137 train_loss= 0.26647 train_acc= 0.95000 train_acc2= 0.91600 time= 214.91707\n",
            "Epoch: 0138 train_loss= 0.26584 train_acc= 0.95000 train_acc2= 0.91600 time= 216.44113\n",
            "Epoch: 0139 train_loss= 0.26520 train_acc= 0.95000 train_acc2= 0.91600 time= 217.97037\n",
            "Epoch: 0140 train_loss= 0.26457 train_acc= 0.95000 train_acc2= 0.91600 time= 219.49735\n",
            "Epoch: 0141 train_loss= 0.26393 train_acc= 0.95000 train_acc2= 0.91600 time= 221.03616\n",
            "Epoch: 0142 train_loss= 0.26330 train_acc= 0.95000 train_acc2= 0.91800 time= 222.56641\n",
            "Epoch: 0143 train_loss= 0.26266 train_acc= 0.95000 train_acc2= 0.91800 time= 224.12517\n",
            "Epoch: 0144 train_loss= 0.26202 train_acc= 0.95000 train_acc2= 0.91800 time= 225.65144\n",
            "Epoch: 0145 train_loss= 0.26138 train_acc= 0.95000 train_acc2= 0.91800 time= 227.19274\n",
            "Epoch: 0146 train_loss= 0.26074 train_acc= 0.95000 train_acc2= 0.91800 time= 228.74070\n",
            "Epoch: 0147 train_loss= 0.26010 train_acc= 0.95000 train_acc2= 0.91800 time= 230.33011\n",
            "Epoch: 0148 train_loss= 0.25945 train_acc= 0.95000 train_acc2= 0.91800 time= 231.86675\n",
            "Epoch: 0149 train_loss= 0.25880 train_acc= 0.95000 train_acc2= 0.92000 time= 233.42596\n",
            "Epoch: 0150 train_loss= 0.25815 train_acc= 0.95000 train_acc2= 0.92000 time= 234.94980\n",
            "Epoch: 0151 train_loss= 0.25750 train_acc= 0.95000 train_acc2= 0.92200 time= 236.48505\n",
            "Epoch: 0152 train_loss= 0.25685 train_acc= 0.95000 train_acc2= 0.92400 time= 237.97885\n",
            "Epoch: 0153 train_loss= 0.25619 train_acc= 0.95000 train_acc2= 0.92400 time= 239.53261\n",
            "Epoch: 0154 train_loss= 0.25554 train_acc= 0.95000 train_acc2= 0.92400 time= 241.05435\n",
            "Epoch: 0155 train_loss= 0.25488 train_acc= 0.95000 train_acc2= 0.92400 time= 242.60023\n",
            "Epoch: 0156 train_loss= 0.25422 train_acc= 0.95000 train_acc2= 0.92400 time= 244.14322\n",
            "Epoch: 0157 train_loss= 0.25359 train_acc= 0.95000 train_acc2= 0.92600 time= 245.69319\n",
            "Epoch: 0158 train_loss= 0.25305 train_acc= 0.95000 train_acc2= 0.92400 time= 247.21473\n",
            "Epoch: 0159 train_loss= 0.25280 train_acc= 0.95000 train_acc2= 0.92200 time= 248.75482\n",
            "Epoch: 0160 train_loss= 0.25346 train_acc= 0.91667 train_acc2= 0.92200 time= 250.27347\n",
            "Epoch: 0161 train_loss= 0.25474 train_acc= 0.95000 train_acc2= 0.92400 time= 251.84097\n",
            "Epoch: 0162 train_loss= 0.25424 train_acc= 0.95000 train_acc2= 0.92800 time= 253.35153\n",
            "Epoch: 0163 train_loss= 0.25009 train_acc= 0.91667 train_acc2= 0.92400 time= 254.88870\n",
            "Epoch: 0164 train_loss= 0.25062 train_acc= 0.95000 train_acc2= 0.92400 time= 256.39789\n",
            "Epoch: 0165 train_loss= 0.25187 train_acc= 0.95000 train_acc2= 0.93000 time= 257.92329\n",
            "Epoch: 0166 train_loss= 0.24843 train_acc= 0.91667 train_acc2= 0.92400 time= 259.43719\n",
            "Epoch: 0167 train_loss= 0.24884 train_acc= 0.95000 train_acc2= 0.92400 time= 260.99918\n",
            "Epoch: 0168 train_loss= 0.24943 train_acc= 0.95000 train_acc2= 0.93200 time= 262.56134\n",
            "Epoch: 0169 train_loss= 0.24656 train_acc= 0.91667 train_acc2= 0.92400 time= 264.11558\n",
            "Epoch: 0170 train_loss= 0.24751 train_acc= 0.95000 train_acc2= 0.92600 time= 265.63070\n",
            "Epoch: 0171 train_loss= 0.24708 train_acc= 0.95000 train_acc2= 0.93000 time= 267.18131\n",
            "Epoch: 0172 train_loss= 0.24495 train_acc= 0.91667 train_acc2= 0.92800 time= 268.71073\n",
            "Epoch: 0173 train_loss= 0.24608 train_acc= 0.95000 train_acc2= 0.92800 time= 270.30997\n",
            "Epoch: 0174 train_loss= 0.24479 train_acc= 0.95000 train_acc2= 0.93000 time= 271.82301\n",
            "Epoch: 0175 train_loss= 0.24355 train_acc= 0.91667 train_acc2= 0.93000 time= 273.38947\n",
            "Epoch: 0176 train_loss= 0.24435 train_acc= 0.95000 train_acc2= 0.92800 time= 274.91220\n",
            "Epoch: 0177 train_loss= 0.24271 train_acc= 0.95000 train_acc2= 0.93000 time= 276.44333\n",
            "Epoch: 0178 train_loss= 0.24217 train_acc= 0.91667 train_acc2= 0.93000 time= 277.96027\n",
            "Epoch: 0179 train_loss= 0.24240 train_acc= 0.95000 train_acc2= 0.93400 time= 279.53859\n",
            "Epoch: 0180 train_loss= 0.24087 train_acc= 0.95000 train_acc2= 0.93000 time= 281.06364\n",
            "Epoch: 0181 train_loss= 0.24068 train_acc= 0.91667 train_acc2= 0.93200 time= 282.61882\n",
            "Epoch: 0182 train_loss= 0.24046 train_acc= 0.95000 train_acc2= 0.93400 time= 284.15398\n",
            "Epoch: 0183 train_loss= 0.23919 train_acc= 0.95000 train_acc2= 0.93000 time= 285.70427\n",
            "Epoch: 0184 train_loss= 0.23905 train_acc= 0.91667 train_acc2= 0.93800 time= 287.21127\n",
            "Epoch: 0185 train_loss= 0.23863 train_acc= 0.93333 train_acc2= 0.93400 time= 288.75241\n",
            "Epoch: 0186 train_loss= 0.23757 train_acc= 0.95000 train_acc2= 0.93200 time= 290.25207\n",
            "Epoch: 0187 train_loss= 0.23733 train_acc= 0.91667 train_acc2= 0.93600 time= 291.80446\n",
            "Epoch: 0188 train_loss= 0.23688 train_acc= 0.93333 train_acc2= 0.93400 time= 293.30607\n",
            "Epoch: 0189 train_loss= 0.23595 train_acc= 0.95000 train_acc2= 0.93200 time= 294.85581\n",
            "Epoch: 0190 train_loss= 0.23555 train_acc= 0.91667 train_acc2= 0.93600 time= 296.34102\n",
            "Epoch: 0191 train_loss= 0.23516 train_acc= 0.95000 train_acc2= 0.93400 time= 297.88471\n",
            "Epoch: 0192 train_loss= 0.23435 train_acc= 0.95000 train_acc2= 0.93400 time= 299.37001\n",
            "Epoch: 0193 train_loss= 0.23376 train_acc= 0.91667 train_acc2= 0.93600 time= 300.91317\n",
            "Epoch: 0194 train_loss= 0.23340 train_acc= 0.95000 train_acc2= 0.93200 time= 302.40448\n",
            "Epoch: 0195 train_loss= 0.23276 train_acc= 0.93333 train_acc2= 0.93600 time= 303.96949\n",
            "Epoch: 0196 train_loss= 0.23201 train_acc= 0.93333 train_acc2= 0.93600 time= 305.46422\n",
            "Epoch: 0197 train_loss= 0.23154 train_acc= 0.95000 train_acc2= 0.93400 time= 307.00527\n",
            "Epoch: 0198 train_loss= 0.23108 train_acc= 0.93333 train_acc2= 0.93600 time= 308.47950\n",
            "Epoch: 0199 train_loss= 0.23039 train_acc= 0.93333 train_acc2= 0.93600 time= 310.02915\n",
            "Epoch: 0200 train_loss= 0.22970 train_acc= 0.95000 train_acc2= 0.93600 time= 311.53677\n",
            "Optimization Finished!\n",
            "Test accuarcy:  0.9259999990463257\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:783: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/manifold/_t_sne.py:793: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "results = defaultdict(list)\n",
        "hidden_emb = None\n",
        "discriminator = Discriminator(in_channels=32, hidden_channels=16, \n",
        "                              out_channels=1) # Comment\n",
        "model2 = ARGVA(encoder, discriminator)\n",
        "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.001)\n",
        "encoder_optimizer = torch.optim.Adam(encoder.parameters(), lr=0.005)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
        "def gae_for():\n",
        "    loss_history = []\n",
        "    val_acc_history = []\n",
        "    t = time.time()\n",
        "    model2.train()\n",
        "    model.train\n",
        "    for epoch in range(200):\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        encoder_optimizer.zero_grad(set_to_none=True)\n",
        "        # mu,logve = encoder(features, adj_norm)\n",
        "        z = model2.encode(features, adj_norm)\n",
        "        for i in range(5):\n",
        "            idx = range(num_nodes)\n",
        "            discriminator.train()\n",
        "            discriminator_optimizer.zero_grad()\n",
        "            discriminator_loss = model2.discriminator_loss(z[idx])  # Comment\n",
        "            discriminator_loss.backward(retain_graph=True)\n",
        "            discriminator_optimizer.step()\n",
        "        recovered, z, mu, logvar = model(features, adj_norm)\n",
        "        loss = criterion(z, tensor_y)  # 计算损失值\n",
        "        loss.backward()\n",
        "        # recovered, z, mu, logvar = model(features, adj_norm)\n",
        "        cur_loss = loss.item()\n",
        "        results['train_elbo'].append(cur_loss)\n",
        "        # if 0 == epoch % 2:\n",
        "            # optimizer.step()\n",
        "            # optimizer.zero_grad(set_to_none=True)\n",
        "        encoder_optimizer.step()\n",
        "        optimizer.step()\n",
        "        train_acc, _, _ = test(tensor_train_mask)  # 计算当前模型训练集上的准确率\n",
        "        val_acc, _, _ = test(tensor_val_mask)  # 计算当前模型在验证集上的准确率\n",
        "        loss_history.append(loss.item())\n",
        "        val_acc_history.append(val_acc.item())\n",
        "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss),\n",
        "              \"train_acc=\", \"{:.5f}\".format(train_acc),\n",
        "              \"train_acc2=\", \"{:.5f}\".format(val_acc),\n",
        "              # \"val_ap=\", \"{:.5f}\".format(ap_curr),\n",
        "              \"time=\", \"{:.5f}\".format(time.time() - t)\n",
        "              )\n",
        "    print(\"Optimization Finished!\")\n",
        "    return loss_history, val_acc_history\n",
        "\n",
        "def test(mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        recovered,z, mu, logvar = model(features, adj_norm)\n",
        "        test_mask_logits = z[mask]\n",
        "        predict_y = test_mask_logits.max(1)[1]\n",
        "        accuarcy = torch.eq(predict_y, tensor_y[mask]).float().mean()\n",
        "    return accuarcy, test_mask_logits.cpu().numpy(),tensor_y[mask].cpu().numpy()\n",
        "\n",
        "def plot_loss_with_acc(loss_history, val_acc_history):\n",
        "    fig = plt.figure()\n",
        "    ax1 = fig.add_subplot(111)\n",
        "    ax1.plot(range(len(loss_history)), loss_history,\n",
        "             c=np.array([255, 71, 90]) / 255.)\n",
        "    plt.ylabel('Loss')\n",
        "\n",
        "    ax2 = fig.add_subplot(111, sharex=ax1, frameon=False)\n",
        "    ax2.plot(range(len(val_acc_history)), val_acc_history,\n",
        "             c=np.array([79, 179, 255]) / 255.)\n",
        "    ax2.yaxis.tick_right()\n",
        "    ax2.yaxis.set_label_position(\"right\")\n",
        "    plt.ylabel('ValAcc')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.title('Training Loss & Validation Accuracy')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "loss, val_acc = gae_for()\n",
        "test_acc, test_logits, test_label = test(tensor_test_mask)\n",
        "print(\"Test accuarcy: \", test_acc.item())\n",
        "\n",
        "plot_loss_with_acc(loss, val_acc)\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE()\n",
        "out = tsne.fit_transform(test_logits)\n",
        "fig = plt.figure()\n",
        "for i in range(7):\n",
        "    indices = test_label == i\n",
        "    x, y = out[indices].T\n",
        "    plt.scatter(x, y, label=str(i))\n",
        "plt.legend(loc=0)\n",
        "plt.savefig('tsne.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "train.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyONou+IszIvqtnveWQBWpXQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}